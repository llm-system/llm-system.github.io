---
title: 深入大模型系统札记：第9章 智能体的认知架构
description: "上下文工程通过四步闭环操纵工作记忆，MCP协议与Agent Skill提供落地实践；目标优化以平均介入间隔为北极星指标，双环引擎在安全边界内持续改进。"
draft: false
---

> **本章概要**：认知架构的核心是两层洞察。**第一层是上下文工程**，核心洞察是上下文是智能体与世界交互的唯一接口，程序记忆通过上下文工程操纵工作记忆，四步闭环（逻辑分区→宏展开→执行→状态更新）是其核心流程。**第二层是目标优化**，智能体以平均介入间隔为北极星指标，通过双环引擎（任务内适应与跨任务优化）在安全边界内持续改进。

---

这一章把前面所有的碎片拼成一张完整的图，是全书的收束与总结。

前八章沿着两条主线展开。**能力构建线**：第三章建立"预训练→微调"的迁移学习范式，第四章通过 Transformer 实现工作记忆外化，第五章通过缩放定律和对齐训练构建大语言模型，第七章通过测试时缩放实现符号推理。**系统构建线**：第五章中 GPT-3 展示的涌现能力揭示了测试时迁移的可能性，第六章将其系统化为上下文学习的三条路径（反刍、RAG、Agentic RAG）并构建语义层（数字孪生），第八章通过 TAO 循环和 Reflexion 机制构建语言智能体的决策闭环和元学习能力。

本章将这些能力整合为一个完整的**认知架构**，其核心是两层洞察：**第一层是上下文工程**，解决智能体如何感知世界、组织信息、执行推理；**第二层是目标优化**，解决智能体如何在安全边界内持续改进自身行为。这两层构成了认知架构的完整图景。

---

## 第一部分：上下文工程

上下文工程是认知架构的信息层。它回答一个核心问题：**智能体如何将外部世界的信息组织成可供推理的形式？**

### 一、核心洞察：上下文即工作记忆

第四章讲"工作记忆外化"，第六章讲"上下文学习"，第八章讲"上下文学习的工作记忆"，本章讲"上下文工程"。这些概念之间是什么关系？

它们指向同一个东西：**上下文是智能体与外部世界交互的唯一接口**。

大语言模型的参数是固定的，无法在推理时修改。智能体要获取新信息、感知环境变化、追踪任务状态，唯一的途径就是通过上下文。上下文不仅是"输入给模型的文本"，更是智能体的**工作记忆**，即模型在单次推理时能够"看到"的全部信息。第四章揭示了 Transformer 的关键特性：仅解码器架构将工作记忆从模型内部状态转移到显式的生成内容中。第六章的上下文学习揭示了这一特性的应用价值：通过精心构造上下文，可以在不修改参数的情况下实现测试时迁移。第八章的 TAO 循环正是利用这种工作记忆机制实现状态追踪和决策闭环。

这引出上下文工程的核心命题：**程序记忆通过上下文工程操纵工作记忆**。程序记忆存储的是"如何构造上下文"的知识：选择什么模板、拉取什么资源、调用什么工具、如何更新状态。每一次任务执行，程序记忆都在动态地组装工作记忆的内容，让模型在正确的上下文中进行推理。这与第六章构建语义层的目标一致：为智能体提供可理解、可导航、可操作的业务语义空间。

上下文工程的本质是**信息的选择、组织与注入**。外部世界的信息是海量的，但上下文窗口是有限的。上下文工程要解决的问题是：在正确的时机，将正确的信息，以正确的格式，呈现给模型。

### 二、最佳实践：四步闭环

程序记忆具体如何操纵工作记忆？上下文工程的流程是什么？

上下文工程是一条非常清晰的**四步闭环**：**逻辑分区**选择对当前任务合适的上下文模板，本质是工作记忆的隔离与延迟加载声明，定义身份/目标/约束/输出格式如何分区、历史与状态放哪一块、工具与资源放哪一块；**宏展开**对模板中声明的宏进行运行时填充，模板不会把内容写死而是声明"我需要什么"（会话历史、任务状态、工具清单、权限边界、外部数据入口），这些必须在运行时拉齐；**执行**进行资源和工具利用，上下文补齐后才开始干活，按标准契约调用工具、读资源、拿到结构化返回，让推理建立在证据上；**状态更新**把工具返回、证据、结论回填进上下文，更新任务状态，同时将本轮交互写入历史记录，再生成最终答案或下一步行动指令，闭环完成。

**渐进式披露**是上下文工程的应有之义。智能体在行动前必须先生成计划，然而，如果智能体甚至不知道自己"能做什么"，它又要如何规划？上下文工程的核心目标正是：每一轮推理开始前，由系统为智能体准备完整、可操作的决策上下文。

**MCP**（Model Context Protocol）正是让这一准备过程实现一致、安全、可重复的协议。MCP 通过三个服务组织上下文：**Prompts**定义工作记忆的逻辑分区（模板 + 占位符），**Resources**提供同步感知的信息资源（会话历史、任务状态），**Tools**声明当前可用的外部行动。关键在于模板中的占位符，它们是渐进式动态加载的入口：

```
[人设] 你是一个自主工作的智能体
[历史] {{mcp:resource:conversation://current/history}}
[可用工具] {{mcp:tool:dynamic_tool_selection}}
[用户问题] {user_input}
```

运行时，上下文工程服务器按六个阶段完成这个闭环：

![上下文工程完整流程](/images/mcp-context-engineering-flow.png)

前三阶段是**渐进式上下文构建**：通过 `list_prompts()` 动态选择最合适的模板获取带占位符的逻辑分区，调用 `get_resource()` 注入环境状态和连续记忆（"我是谁、我刚做了什么"），通过 `list_tools()` 智能筛选为 LLM 构建精准的行动空间而不是把所有工具一股脑塞进去。后三阶段是**推理-执行-更新**：LLM 基于完整上下文进行高效规划输出结构化的 `tool_calls`，系统执行工具调用并收集 `tool_outputs`，通过 `add_conversation_turn()` 将本轮交互写入历史闭环完成；如果需要多轮推理，基于更新后的资源状态继续下一轮循环。

MCP 的价值在于**可发现性**（智能体通过 `list_tools` 获得完整的行动空间）和**标准化**（所有行动都被抽象为"选择工具→生成 JSON 指令→接收 JSON 返回"的统一循环）。

Anthropic 的**Agent Skill**覆盖了上下文工程最佳实践的高频动线。Skill 本质是预封装的上下文工程单元：目录结构定义边界，SKILL.md 声明所需的 Resources 和 Tools，脚本实现具体逻辑。智能体先看技能的元数据判断相关性，只有确定相关时才加载完整内容。这正是渐进式披露在应用层的具体实现。

---

## 第二部分：目标优化

上下文工程解决了"智能体如何感知和行动"的问题，但没有回答"智能体如何变得更好"。目标优化是认知架构的第二层，它回答一个核心问题：**智能体如何在安全边界内持续改进自身行为？**

### 三、北极星指标

智能体上线后，运营团队需要一个核心指标来衡量系统的成熟度。

答案是**平均介入间隔**（Miles Per Intervention，简称 MPI）。这一概念借用自动驾驶领域，指智能体在需要人工介入之前能够自主完成多少任务。具体的度量方式取决于业务场景：在客服系统中，MPI 可以是"每处理多少个工单需要人工接管一次"；在代码生成场景中，可以是"每完成多少个任务需要开发者修正一次"；在数据分析场景中，可以是"每生成多少份报告需要分析师校验一次"。平均介入间隔越高，智能体的自主性越强，运营成本越低。

平均介入间隔之所以是北极星指标，是因为它直接反映了智能体系统的核心价值主张：**用 AI 替代人工处理重复性任务**。如果智能体每处理 10 个工单就需要人工介入一次（MPI = 10），那它的实际价值就大打折扣；当 MPI 提升到 100，意味着一个人可以"管理"100 倍的任务量。**提高平均介入间隔是智能体系统持续优化的核心目标**，所有的架构设计、工程实践、运营策略，最终都要服务于这个指标的提升。

### 四、安全边界：护栏与人在回路

追求高平均介入间隔的同时，如何确保智能体不会做出危险的决策？

目标优化必须在安全边界内进行。**安全护栏**设定边界，决定什么情况下必须触发人工介入。护栏是以代码形式固化的、确定性的安全机制，以最高执行优先级运行，大语言模型生成的任何推理结果都不能凌驾于其上。护栏定义了**不可逾越的红线**（禁止执行某类高风险操作、禁止访问敏感数据）和**需要人工确认的黄线**（超过某个金额的交易、涉及用户隐私的操作）。

**人在回路**（Human-in-the-Loop，简称 HITL）是人工介入的执行机制。当智能体触碰护栏定义的边界时，系统暂停自主执行，将决策权交还给人类。人在回路不是失败，而是系统设计的一部分，确保在智能体能力边界之外的场景中人类仍然保持最终控制权。

护栏和人在回路的关系是：**护栏定义"何时介入"，人在回路定义"如何介入"**。两者协同确保智能体在安全边界内优化。更重要的是，人在回路介入产生的数据是智能体学习的宝贵资源，人类的决策模式正是智能体需要学习的目标行为。

### 五、双环引擎：任务内适应与跨任务优化

智能体如何在安全边界内持续改进？答案是**双环引擎**，由"内循环"和"外循环"构成的优化机制，这正是第八章讨论的元学习结构在认知架构中的具体实现。

**内循环**是任务内的即时适应。智能体接收新任务时，从参数先验中激活通用知识，利用工作记忆维持任务状态，通过 ReAct 的"思考→行动→观察"循环快速构建行动路径。内循环不修改模型参数，完全依赖上下文工程实现即时适应。

**外循环**是跨任务的长期优化。当任务完成或失败时，外循环启动：评估本次执行的效果，生成反思，将有价值的经验存入情节记忆，在未来的内循环中作为经验先验被调用。外循环通过情节记忆实现跨任务的知识积累。

### 六、情节记忆：知识升维与终身学习

情节记忆是外循环的核心机制。它解决一个关键问题：上下文工程让智能体能够在单次任务中进行可控推理，但工作记忆受上下文窗口的容量限制，任务结束后经验便会消失。如何让智能体具备终身学习能力？

答案是**情节记忆的三层架构**，即"在线写入→近线处理→离线反思→在线检索"的闭环，其核心是**知识升维**。在线层负责事件的即时写入，以高保真、结构化的方式持久化存储；近线层异步消费原始事件流，进行解析、标准化、语义向量化、索引构建；当上下文窗口逼近容量上限时，触发离线反思。离线反思的核心是**分层知识模型**，实现从具体案例到通用原则的知识升维：第零层是原始证据层，存储所有结构化事件记录作为事实基础；第一层是模式层，通过聚合分析形成可复用的行动模式（例如"购买跑鞋的用户有百分之六十概率购买运动配件"）；第二层是原则层，通过再次归纳提炼跨场景的指导原则（例如"提升客单价的核心是推荐生态互补型商品，而非同类竞争型商品"）。

情节记忆的价值通过两条路径释放，分别对应两个优化层次：

**在线检索**服务于内循环的即时适应。核心机制是**缺口检测**：先尝试仅依赖当前上下文对问题进行"自答"，若存在信息缺口则生成检索计划，从情节记忆中补全历史经验。这条路径不修改模型参数，通过上下文工程实现能力扩展。

**后训练**服务于外循环的长期优化。情节记忆积累的高质量交互数据（尤其是人在回路介入后人类的决策模式）可以作为微调数据，将验证有效的经验固化到模型参数中。这条路径与第五章的在线环境对齐形成闭环：第五章讨论的基于人类反馈的强化学习需要人类偏好数据，而情节记忆正是这些数据的来源；第八章的 Reflexion 机制将反思经验语言化存储，这些语言化经验既可以通过上下文注入即时使用，也可以作为监督微调数据固化到参数中。模型在实际运行中积累经验，经验反哺模型训练，训练后的模型在运行中表现更好，形成终身学习的完整闭环。

认知架构不只是理论框架，它正在成为产品。Anthropic 的**Cowork**是商业端的典型案例，面向非技术用户的自主智能体，能访问用户授权的本地文件夹，自主完成知识工作任务。开源社区的**OpenClaw**则走了另一条路：用户在本地硬件（如 Mac mini）上运行智能体，通过 WhatsApp 等消息应用交互，拥有文件系统、浏览器、Shell 的完整访问权限，数据和技能完全在本地。两者的共同点是：通过技能系统实现上下文工程，通过授权机制实现安全边界，追求的核心指标都是高 MPI。这类产品的出现，无论商业还是开源，都印证了本章的核心论点：**认知架构让智能体得以从理论走向生产**。

---

## 小结

本章作为全书的收束，将前八章的能力整合为一个完整的认知架构。认知架构的核心是两层洞察：

**第一层是上下文工程**，解决智能体如何感知世界、组织信息、执行推理。核心洞察是**上下文是智能体与世界交互的唯一接口**，程序记忆通过上下文工程操纵工作记忆。四步闭环（逻辑分区→宏展开→执行→状态更新）是其核心流程，MCP 等协议标准和 Skill 等工程实践为这一层提供了可落地的最佳实践。这一层串联了第四章的工作记忆外化、第六章的上下文学习与语义层构建、第八章的 ReAct 决策闭环。

**第二层是目标优化**，解决智能体如何在安全边界内持续改进自身行为。平均介入间隔是北极星指标，护栏和人在回路定义安全边界，双环引擎（内循环的任务内适应、外循环的跨任务优化）是优化机制，情节记忆通过知识升维（证据→模式→原则）支撑终身学习。Cowork 等产品的出现证明了认知架构可以从理论框架落地为面向终端用户的数字员工。这一层串联了第五章的对齐训练、第八章的 Reflexion 机制，形成"运行→积累→训练→改进"的完整闭环。

回顾全书，构建大模型系统的核心挑战已从「参数规模」转向「工程打磨」：**可靠性**（第七章的结构化推理、护栏机制）、**可验证性**（第六章的语义层、平均介入间隔指标）、**可治理性**（第五章的对齐训练、人在回路）。

认知架构是这些能力的集成框架，让我们能够打造面向开放世界、具备终身学习能力的智能体系统。

**大模型系统是一个仍在快速演进的领域**，没有哪个团队一开始就规划好了从 GPT-3 到语言智能体的完整路线图，很多关键突破都是"试出来"的。**现在是参与这个领域最好的时机。**技术框架已经基本成型，但应用落地才刚刚开始。无论你是研究者、工程师、产品经理还是创业者，都有机会在这个领域留下自己的印记。这本书给你的是地图，路要你自己走。

## 引用本章

```bibtex
@book{baillmsystem,
  title     = {深入大模型系统：提示工程、符号推理与智能体实践},
  author    = {Bai, Yu},
  publisher = {人民邮电出版社},
  year      = {2025},
  isbn      = {978-7-115-68707-4}
}
```

## 文献列表

- **CoALA: 语言智能体的认知架构**
  Cognitive Architectures for Language Agents. Sumers, Theodore et al. arXiv 2023.
  [原文](https://arxiv.org/abs/2309.02427)
- **Generative Agents: 生成式智能体的交互模拟**
  Generative Agents: Interactive Simulacra of Human Behavior. Park, Joon Sung et al. UIST 2023.
  [原文](https://arxiv.org/abs/2304.03442)
- **MemGPT: 面向无界上下文的操作系统式大语言模型**
  MemGPT: Towards LLMs as Operating Systems. Packer, Charles et al. arXiv 2023.
  [原文](https://arxiv.org/abs/2310.08560)
- **Voyager: 开放世界的具身智能体**
  Voyager: An Open-Ended Embodied Agent with Large Language Models. Wang, Guanzhi et al. arXiv 2023.
  [原文](https://arxiv.org/abs/2305.16291)
- **模型上下文协议**
  Model Context Protocol. Anthropic. 2024.
  [规范](https://modelcontextprotocol.io/) [介绍](https://www.anthropic.com/news/model-context-protocol)
- **智能体技能**
  Agent Skills. Anthropic. 2025.
  [介绍](https://www.anthropic.com/news/skills) [工程实践](https://www.anthropic.com/engineering/equipping-agents-for-the-real-world-with-agent-skills)
- **Cowork：认知架构的商业产品化**
  Cowork: Claude Code for the rest of your work. Anthropic. 2026.
  [原文](https://claude.com/blog/cowork-research-preview)
- **OpenClaw：认知架构的开源实现**
  OpenClaw: The AI that actually does things. @steipete. 2026.
  [原文](https://openclaw.ai/) [代码](https://github.com/openclaw/openclaw)
- **构建有效智能体**
  Building effective agents. Anthropic. 2024.
  [原文](https://www.anthropic.com/research/building-effective-agents)
- **上下文工程**
  What is context engineering? Anthropic. 2025.
  [原文](https://www.anthropic.com/news/what-is-context-engineering)
