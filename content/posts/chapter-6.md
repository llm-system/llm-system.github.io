---
title: 深入大模型系统札记：第6章 提示工程方法
description: "测试时迁移学习的三条路径：来自模型自身的反刍、来自外部的RAG、来自自组织查询的Agentic RAG；本体构建作为语义层的最终形态，实现组织的数字孪生。"
draft: false
---

> **本章概要**：前面的章节讨论了训练时迁移学习，本章讨论**测试时迁移学习**，在模型参数固定后，通过构造上下文来引导模型适应新任务。提示工程的本质是上下文工程，核心问题是"上下文从哪里来"。**第一层是借由上下文学习完成测试时迁移学习**，三条技术路径：来自模型自身（反刍）、来自外部（RAG）、来自自组织查询（Agentic RAG）。**第二层是本体构建**，本体是语义层的最终形态，通过语义层建模将异构数据源统一为组织的数字孪生。

---

这一章讨论的是**如何用好模型**，而不是如何训练模型，对大多数开发者和企业来说，这才是真正的战场。

模型是给定的（无论是 API 还是开源模型），你能掌控的是上下文。太多团队花大量精力在"选哪个模型"上，却忽视了"如何构造上下文"。方向错了。**上下文工程是性价比最高的优化方向**。

前面的章节讨论了**训练时迁移学习**，通过预训练和后训练，让模型获得可迁移的通用能力。本章讨论**测试时迁移学习**，在模型参数固定后，通过构造上下文来引导模型适应新任务。

这是大模型区别于传统机器学习的关键能力。传统模型要适应新任务，必须收集数据、重新训练；大模型通过上下文学习，可以在推理时"现学现用"。GPT-3 的关键发现是：只需在输入中嵌入少量示例，模型无需任何参数更新就能"学会"执行新任务。这意味着模型可以在开放世界中动态解决问题，训练时没见过的任务、没见过的数据，都可以通过构造合适的上下文来应对。

提示工程的本质就是**上下文工程**：如何为模型构造最有效的上下文，让它在测试时获得执行任务所需的能力。核心问题是：**上下文从哪里来？**

本章从两个层次展开：

**第一层：借由上下文学习完成测试时迁移学习**。根据上下文来源不同，形成三条技术路径：**来自模型自身（反刍）**，把模型本身当作知识库查询，将参数中的隐式知识显式化；**来自外部（RAG）**，通过检索从外部数据源获取上下文，但检索规则由人类预设；**来自自组织查询（Agentic RAG）**，让智能体自主决定如何查询，根据任务需求动态规划检索策略。

**第二层：本体构建**。智能体要从外部获取上下文，前提是存在一个可供查询的语义层。语义层的最终形态是**本体（Ontology）**，组织的数字孪生。本体不是简单地暴露各数据源的查询接口，而是通过语义层建模将异构数据源统一到一个语义空间中。

---

## 第一部分：借由上下文学习完成测试时迁移学习

**上下文学习（In-Context Learning, ICL）**是测试时迁移学习的核心机制。GPT-3 的关键发现是：通过在输入中嵌入少量示例，模型无需任何参数更新就能"学会"执行新任务 (Brown et al., 2020)。这意味着模型可以通过上下文动态获得新能力，而不需要修改参数，在推理时完成迁移学习。

核心问题是：**上下文从哪里来？**

### 一、上下文来自模型自身（反刍）

最直接的上下文来源是模型自身。模型在预训练过程中已经从海量文本中学习了大量知识，这些知识以参数的形式隐式存储在模型中。**知识生成提示（Generated Knowledge Prompting, GKP）**的核心思想就是让模型"反刍"自己的参数知识 (Liu et al., 2022)：先让模型生成相关背景知识，再用这些知识增强主任务的上下文，相当于先"查询"模型内部的知识库，再用查询结果辅助推理。

### GKP 的工作流程

考虑一个常识推理问题："鲸鱼是鱼类，对还是错？"直接提问时，模型可能因为"鲸鱼"名称中有"鱼"字而错误回答"对"。GKP 的策略是先向模型的内部知识库"查询"相关知识：第一步是知识生成，让模型先回忆关于鲸鱼的生物学知识，模型会生成类似"鲸鱼是哺乳动物，用肺呼吸，胎生，体温恒定，幼崽吃母乳；鱼类是用鳃呼吸的冷血动物"这样的知识；第二步是知识注入与推理，将生成的知识作为上下文再回答原问题，有了"鲸鱼是哺乳动物，用肺呼吸"这个背景知识，模型就能正确回答"错"。GKP 将模型参数中隐式存储的知识转化为显式的上下文信息，这个显式化过程有两个作用：让相关知识进入模型的注意力范围，消除名称带来的误导。

### 局限：受限于模型参数

反刍的核心局限是：它只能提取模型参数中已经存在的知识。如果问题涉及模型训练截止日期之后的信息、企业私有数据、或专业领域的长尾知识，模型参数中根本不存在相关知识，无论如何"激活"都无法获得。

这引出了下一个问题：如何从外部获取上下文？

### 二、上下文来自外部（RAG）

**RAG（Retrieval-Augmented Generation）**让上下文来自外部知识库的检索 (Lewis et al., 2020)。核心思想是：在生成前先从外部知识库检索相关信息，将其注入上下文，将 LLM 从"闭卷考试"转变为"开卷考试"。

本节介绍的是**朴素 RAG**，最基础的检索增强范式。

### RAG 的工作流程

一个标准的 RAG 流程分为四步：用户提问（比如"我们公司上季度的销售额是多少？"）→ 系统检索（将问题转化为向量，从企业知识库中检索相关文档）→ 上下文注入（将检索到的文档拼接在问题前面）→ 模型生成（基于注入的上下文生成答案）。在这个流程中，智能体只负责"理解问题"和"生成答案"，检索决策完全由系统根据用户查询自动执行，智能体不知道有哪些知识库可用，不参与检索策略的选择，也不能根据检索结果调整查询。

### RAG 的技术栈

RAG 系统的技术栈可以分为三层：**索引层**、**检索层**、**融合层**。

**索引层**将原始文档转化为可检索的形式，核心是"切分→编码→索引"三个步骤。文档切分将长文档分割为语义完整的片段，切分策略（固定长度、语义边界、滑动窗口、递归切分）直接影响检索质量。片段大小的选择不是拍脑袋定的"经验值"，而应基于线上用户查询长度的分布，因为 embedding 模型的工作原理决定了**信息粒度接近的内容才是更可比的**，文档片段过长而查询很短会导致语义匹配失准。语义编码将文本片段映射到高维向量空间，本质上是**现实世界语义在几何空间的数字孪生**，用几何距离表示现实世界的相关性，让语义相近的文本在向量空间中相邻。向量索引组织向量以支持高效的近似最近邻搜索，FAISS 是主流开源库 (Johnson et al., 2017)，典型配置是先用聚类算法缩小搜索范围，再用图算法做精细检索。

**检索层**根据查询找到相关文档 (Karpukhin et al., 2020)，常见的做法是两阶段检索：第一阶段快速召回大量候选，第二阶段精细排序筛选最相关的。ColBERT 提出了"延迟交互"范式 (Khattab & Zaharia, 2020)，在保留密集表示高效索引优势的同时实现 token 级精细匹配，成为精排阶段的重要选择。**融合层**将检索结果与查询整合 (Izacard & Grave, 2020)，最简单的方式是直接把检索到的文档拼接在问题前面作为上下文，更高级的方式是让模型在生成时动态关注不同的文档。

### 结构化数据的检索

上述技术栈主要针对非结构化文本。对于结构化数据，有专门的检索技术。

Text-to-SQL 技术将自然语言转化为数据库查询 (Yu et al., 2018)：用户用自然语言提问，模型基于数据库结构生成查询语句，执行后返回结果。DIN-SQL (Pourreza & Rafiei, 2023) 将这一过程分解为四个子任务：识别相关表列、判断查询类型、生成查询语句、自我修正，在业界标准测试中达到最佳效果。

TableQA 技术让模型直接在表格上问答 (Herzig et al., 2020)。TAPAS 模型通过特殊的位置编码理解表格的行列结构，比把表格转成文本更好地保留结构信息。这里的思路和视觉领域的 LLaVA (Liu et al., 2023)、BLIP-2 (Li et al., 2023) 是同一个范式：**专用编码器负责理解非文本模态（表格结构、图像像素），通过对齐层将其映射到语言模型的语义空间，再由 LLM 完成推理和生成**。表格编码器理解行列关系，视觉编码器理解空间结构，本质上都是为 LLM 嫁接"新的感知通道"。这两种技术互补：Text-to-SQL 解决"如何从数据库查询"，TableQA 帮助模型理解查询返回的结果表。

知识图谱的检索以"实体-关系-实体"三元组组织知识，支持结构化的多跳推理。例如，回答"特斯拉 CEO 的母校是哪所大学？"需要沿关系链推理：先找到特斯拉的 CEO 是马斯克，再找到马斯克的母校是宾夕法尼亚大学。这是向量检索难以实现的，向量只能找到"语义相似"的文档，无法沿明确的关系链推理。GraphRAG (Edge et al., 2024) 将知识图谱引入检索增强框架：从查询中识别关键实体，以实体为起点检索相关子图，沿路径收集事实，最终生成答案。

### RAG 的局限

朴素 RAG 有两个结构性局限。

第一个是**断章取义**。为了检索，长文档必须被切分为片段；但切分后，每个片段都失去了原有的上下文。举个具体的例子：一份供应商评审报告中写道"该供应商在 2022 年质检评审中获得 A 级评定，供货质量优异。但 2023 年复审中因多次交付不合格品，评级已降为 C 级，建议暂停合作。"如果切片恰好只保留了前半句，用户问"这个供应商的质检评级是多少？"时，模型会基于片段自信地回答"A 级"——而事实恰恰相反，片段的表意与段落的表意完全矛盾。虽然滑动窗口、上下文扩充等方法可以在一定程度上缓解，但这类问题是**结构性的**——转折、否定、条件限定、时态变迁等语义断裂模式千变万化，没有哪一套切分与扩充规则能穷举所有情况。这个问题在后续的本体构建中才能从根本上缓解，结构化的本体保留了实体间的关系与状态变迁，不会像文本切分那样丢失上下文。

第二个是**被动性**。检索规则由人类预先设定，而非由智能体根据任务需求动态决定。系统设计者基于先验知识定义了查询如何转化为 embedding、匹配什么索引、返回多少文档、如何排序融合，智能体只是被动接收这些规则下的检索结果。

问题在于：人类的先验假设不一定符合 LLM 的实际需求。用户的原始查询可能表述模糊，embedding 相似度可能错过关键信息，固定的 top-k 可能遗漏或引入噪声，这些都是人类预设规则的局限，而智能体对此无能为力。它不知道检索到的是否足够，不知道还需要什么，更不知道应该换一种方式查询。

考虑这个问题："特斯拉的市值是苹果的多少倍？"

RAG 系统会将这个问题做 embedding 匹配，可能检索到一些包含"特斯拉"、"苹果"、"市值"关键词的文档。但智能体无法判断：检索到的数据是否是最新的？是否遗漏了关键信息？是否应该分别查询两家公司的市值再做计算？这些决策都超出了预设检索规则的能力范围。

这两个局限指向一个更高级的形态：让智能体自己决定如何查询。

### 三、上下文来自自组织查询（Agentic RAG）

**Agentic RAG** 是上下文学习的最高形态。与朴素 RAG 依赖人类预设规则不同，Agentic RAG 让智能体**自主决定**何时查询、查询什么、如何利用查询结果，从"人类设计查询规则"演进为"智能体自己决定如何查询"。智能体根据任务需求动态规划检索策略，根据返回结果调整下一步行动，实现真正的自主获取上下文。

### 智能体的雏形：行动-观察闭环

Self-Ask (Press et al., 2022) 展示了最干净的"行动-观察"循环：智能体提出问题，获得答案，再基于答案决定下一个问题。举个例子：用户问"超导现象被发现时，谁是美国总统？"智能体不会直接回答，而是自主分解为子问题——首先问"超导现象是什么时候被发现的？"得到答案"1911 年"，然后问"1911 年谁是美国总统？"得到答案"威廉·霍华德·塔夫脱"，最后综合得出最终答案。这与 RAG 的本质区别在于：RAG 是系统根据用户原始查询执行一次检索，Agentic 是智能体自己规划多次查询，每次查询都是智能体主动发起的。

从三种上下文来源的对比看：反刍（GKP）把模型本身当作知识库来查询，RAG 和 Agentic RAG 的上下文都来自外部语义层；从查询决策者看，反刍由提示设计者决定查询什么知识，RAG 的查询规则由人类预先设定，而 Agentic RAG 由智能体自己决定如何查询；从查询模式看，RAG 是单次触发，Agentic RAG 是多轮迭代；从策略调整能力看，只有 Agentic RAG 能根据返回结果动态调整下一步策略。Agentic RAG 实现了真正的交互式语义层推理：智能体在语义层上自主导航、查询、整合信息，形成闭环的推理过程。

本章只讨论 Agentic RAG 在上下文获取层面的特征。完整的智能体系统还需要更多能力：第七章讨论符号推理方法，第八章讨论语言智能体的构建（TAO 循环、长期记忆机制），第九章讨论完整的认知架构（工作记忆、程序记忆、语义记忆、情节记忆、进化闭环）。这里有一个常见误区你要避免：**不是所有场景都需要 Agentic RAG**。很多时候，一个设计良好的 RAG 系统就够用了。Agentic RAG 的优势在于灵活性，代价是复杂性和不可预测性。选择哪种范式，取决于你的场景对"可控性"和"灵活性"的权衡，盲目追求"更智能"的方案，往往适得其反。

### 从查询到自治：本体的必要性

Agentic RAG 的行动-观察闭环让智能体具备了自主获取上下文的能力，但这只是起点。真正的价值在于**自治完成任务**：智能体不仅能查询信息，还能在业务系统中执行操作，创建订单、调整库存、触发工作流。

这就引出一个关键前提：智能体要自治工作，必须有一个**可供查询和操作的语义层**。这个语义层不能只是零散的数据源和 API，而必须是一个统一的、智能体能理解的业务世界模型。这就是**本体**——组织的数字孪生。

---

## 第二部分：本体构建

第一部分讨论了"上下文从哪里来"，其中 RAG 部分介绍了文本数据的处理（切分、编码、索引）。但无论是 RAG 还是 Agentic RAG，都有一个更深层的前提：**存在一个可供查询和操作的本体**。

本体是语义层的最终形态，组织的数字孪生。

### 四、本体：语义层的统一形态

**本体（Ontology）**是"数据到有意义语义概念的系统映射"。它将分散在各系统中的数字资产与现实世界的对应物连接起来，从工厂、设备、产品等实物资产，到客户订单、金融交易等业务概念。本体充当组织的**数字孪生**，是智能体理解和操作业务的语义底座。

### 本体的核心元素

一个完整的本体包含三类元素：**语义元素**定义对象（Object）、属性（Property）、链接（Link），这是静态的业务概念模型；**动态元素**定义操作（Action）、函数（Function），这让智能体能够在本体上执行动作；**安全元素**定义动态访问控制，确保智能体只能访问和操作授权范围内的数据。

### 语义层建模语言

直接将数据库结构暴露给智能体存在问题：技术术语与业务语言不匹配，缺乏业务逻辑定义，复杂的表关联关系难以理解。语义层建模语言在原始数据库结构之上定义业务语义，常见的有 LookML 和 dbt semantic layer。

以 LookML 为例，它可以定义一个"订单"视图，包含订单编号、客户编号、创建时间等维度，以及总收入、平均订单金额等指标。智能体不需要理解底层数据库结构，只需要理解这些业务概念。当用户问"按区域查看本季度收入趋势"时，可以直接映射到语义层的概念上，再由系统翻译为具体的数据库查询。

但单一数据源的语义层有其局限。企业数据分散在多个系统中，ERP 存储订单，CRM 存储客户，知识库存储文档，知识图谱存储领域关系。本体的核心价值在于将这些异构数据源统一到一个语义空间中。

### 从数据源到本体

RAG 部分介绍了各类数据源的检索技术，文本的向量检索、数据库的 Text-to-SQL、知识图谱的 GraphRAG。这些技术解决的是"如何查询"的问题。本体要解决的是更上层的问题：如何将这些异构数据源统一到一个语义空间中，形成组织的数字孪生。

以一个制造企业为例：ERP 系统存储订单、客户、产品等业务数据；知识图谱存储产品-原材料-供应商的关系链；文档库存储操作规程和故障处理流程。本体不是简单地把这些数据源的查询接口暴露给智能体，而是在更高层次上定义统一的业务概念模型，"订单"是什么、"客户"和"订单"如何关联、可以对"订单"执行哪些操作。

语义层建模语言（如 LookML）是构建本体的技术手段。它为每个数据源定义语义层，然后将这些语义层整合为统一的本体。最终形成的本体是组织的数字孪生：它不仅是数据的聚合，更是业务逻辑的形式化表达。Palantir Foundry 是这一理念的工业级实现，其核心就是构建企业级的统一本体 (Palantir, 2024)。

### OAG：从检索到本体

RAG 强调"检索"（Retrieval），但检索只是手段，目的是让 LLM 获取正确的上下文。**OAG（Ontology Augmented Generation，本体增强生成）**更好地表达了这一理念：LLM 不仅能检索数据，还能利用本体中的**确定性逻辑工具**（预测模型、优化器、规则引擎）和**操作**，通过本体与源系统形成闭环。

考虑一个场景：某配送中心遭遇火灾，需要评估对客户的影响并制定应对方案。

传统 RAG 的能力边界是：检索相关文档，比如库存记录、客户订单、供应商信息，然后生成一段文字描述。

OAG 的能力则大大扩展：它可以通过本体查询受影响的库存、关联的客户订单、替代供应商；可以调用预测模型评估短缺风险；可以调用优化器生成最优的库存调配方案；还可以执行实际操作，比如自动创建调拨单、通知相关客户、更新交付时间。

OAG 将大语言模型锚定在组织的业务现实中。每一个回答都可以追溯到本体中的具体数据源，每一个操作都通过本体中定义的动作执行。这解决了大语言模型的两个核心问题：幻觉问题，因为回答基于本体中的真实数据；可审计性问题，因为模型可以"展示其工作"，引用具体来源。

### 从语义层到操作层

传统的语义层是"只读"的，智能体只能查询数据。本体的关键突破是引入**操作层**：智能体不仅能理解业务，还能在业务上执行动作。Palantir AIP 在 Foundry 本体之上实现了这一点，将本体中定义的"动态元素"（操作、函数）暴露给 LLM，使其能够创建订单、调整产能、触发工作流、调用预测模型 (Oracle & Palantir, 2024)。

通过操作，本体从"数据的语义表示"升级为"业务的可执行模型"。智能体在本体上不仅能"看"，还能"做"，这是 Agentic RAG 落地的前提。

---

## 小结

本章的核心是**测试时迁移学习**：在模型参数固定后，通过构造上下文来引导模型适应新任务。提示工程的本质是上下文工程，核心问题是"上下文从哪里来"。

**第一层：借由上下文学习完成测试时迁移学习**。三条技术路径：**来自模型自身（反刍）**，GKP 让模型反刍自身参数知识，将隐式知识显式化为上下文，但受限于模型参数中已有的知识；**来自外部（RAG）**，从外部数据源检索（文本、数据库、知识图谱），但检索规则由人类预设，智能体被动接收结果；**来自自组织查询（Agentic RAG）**，让智能体自主决定如何查询，根据任务需求动态规划检索策略，这是上下文学习的最高形态。

**第二层：本体构建**。本体是语义层的最终形态，组织的数字孪生。它不是简单地暴露各数据源的查询接口，而是通过语义层建模语言将异构数据源统一到一个语义空间中，定义统一的业务概念模型。OAG（本体增强生成）将大语言模型锚定在业务现实中，支持在本体上执行确定性操作。

本体是智能体理解和操作业务的语义底座。它将语义层从"只读"升级为"可操作"，智能体不仅能查询数据，还能在本体上执行动作，形成与业务系统的闭环。

---

## 引用本章

```bibtex
@book{baillmsystem,
  title     = {深入大模型系统：提示工程、符号推理与智能体实践},
  author    = {Bai, Yu},
  publisher = {人民邮电出版社},
  year      = {2025},
  isbn      = {978-7-115-68707-4}
}
```

## 文献列表

- **GPT-3: 语言模型是少样本学习者**
  Language Models are Few-Shot Learners. Brown, Tom B. et al. NeurIPS 2020.
  [原文](https://arxiv.org/abs/2005.14165)
- **GKP: 生成知识提示**
  Generated Knowledge Prompting for Commonsense Reasoning. Liu, Jiacheng et al. ACL 2022.
  [原文](https://arxiv.org/abs/2110.08387)
- **Self-Ask: 自我提问机制**
  Measuring and Narrowing the Compositionality Gap in Language Models. Press, Ofir et al. EMNLP 2023.
  [原文](https://arxiv.org/abs/2210.03350)
- **RAG: 检索增强生成**
  Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks. Lewis, Patrick et al. NeurIPS 2020.
  [原文](https://arxiv.org/abs/2005.11401)
- **DPR: 密集段落检索**
  Dense Passage Retrieval for Open-Domain Question Answering. Karpukhin, Vladimir et al. EMNLP 2020.
  [原文](https://arxiv.org/abs/2004.04906)
- **FiD: Fusion-in-Decoder**
  Leveraging Passage Retrieval with Generative Models for Open Domain Question Answering. Izacard, Gautier and Grave, Edouard. EACL 2021.
  [原文](https://arxiv.org/abs/2007.01282)
- **FAISS: 向量搜索库**
  Billion-scale similarity search with GPUs. Johnson, Jeff et al. IEEE TBD 2017.
  [原文](https://arxiv.org/abs/1702.08734)
- **Spider: Text-to-SQL 基准**
  Spider: A Large-Scale Human-Labeled Dataset for Complex and Cross-Domain Semantic Parsing and Text-to-SQL Task. Yu, Tao et al. EMNLP 2018.
  [原文](https://arxiv.org/abs/1809.08887)
- **DIN-SQL: Text-to-SQL 分解方法**
  DIN-SQL: Decomposed In-Context Learning of Text-to-SQL with Self-Correction. Pourreza, Mohammadreza and Rafiei, Davood. NeurIPS 2023.
  [原文](https://arxiv.org/abs/2304.11015)
- **TAPAS: 表格问答**
  TAPAS: Weakly Supervised Table Parsing via Pre-training. Herzig, Jonathan et al. ACL 2020.
  [原文](https://arxiv.org/abs/2004.02349)
- **LLaVA: 大语言视觉助手**
  Visual Instruction Tuning. Liu, Haotian et al. NeurIPS 2023.
  [原文](https://arxiv.org/abs/2304.08485)
- **BLIP-2: 视觉语言预训练**
  BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models. Li, Junnan et al. ICML 2023.
  [原文](https://arxiv.org/abs/2301.12597)
- **GraphRAG: 图检索增强生成**
  From Local to Global: A Graph RAG Approach to Query-Focused Summarization. Edge, Darren et al. arXiv 2024.
  [原文](https://arxiv.org/abs/2404.16130)
- **Palantir Foundry: 本体与数字孪生**
  Palantir Foundry Documentation. Palantir Technologies. 2024.
  [原文](https://www.palantir.com/docs/foundry/ontology/overview/)
- **Palantir AIP on OCI: 企业级 AI 平台**
  Run Palantir Foundry and Artificial Intelligence Platform on OCI. Oracle & Palantir. 2024.
  [原文](https://docs.oracle.com/en/solutions/palantir-foundry-ai-platform-on-oci/)
- **Sentence-BERT: 句子嵌入**
  Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks. Reimers, Nils and Gurevych, Iryna. EMNLP 2019.
  [原文](https://arxiv.org/abs/1908.10084)
- **RAG Survey: RAG 综述**
  Retrieval-Augmented Generation for Large Language Models: A Survey. Gao, Yunfan et al. arXiv 2024.
  [原文](https://arxiv.org/abs/2312.10997)
- **ColBERT: 基于延迟交互的高效段落检索**
  ColBERT: Efficient and Effective Passage Search via Contextualized Late Interaction over BERT. Khattab, Omar and Zaharia, Matei. SIGIR 2020.
  [原文](https://arxiv.org/abs/2004.12832)