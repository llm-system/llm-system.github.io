---
title: 术语表
---


- **上下文学习（ICL, In-Context Learning）**：模型通过观察输入中的示例（few-shot examples）来学习执行任务，无需更新模型参数。 ([Wikipedia](https://en.wikipedia.org/wiki/In-context_learning_(natural_language_processing)))
- **上下文窗口（Context Window）**：模型在一次处理中能够考虑的最大输入序列长度，限制了模型能够「看到」的上下文范围。 ([Wikipedia](https://en.wikipedia.org/wiki/Context_window))
- **交叉注意力（Cross-Attention）**：注意力机制的一种，其中查询来自一个序列，而键和值来自另一个序列，常用于编码器-解码器架构中。 ([Wikipedia](https://en.wikipedia.org/wiki/Attention_(machine_learning)#Cross-attention))
- **人工智能（Artificial Intelligence, AI）**：使机器能够执行通常需要人类智能的任务的技术与系统，包括学习、推理、感知、理解自然语言等能力。 ([Wikipedia](https://en.wikipedia.org/wiki/Artificial_intelligence))
- **HUMAN-IN-LOOP（人类监督闭环）**：在关键节点引入人工审核、纠错或批准的机制，用于在安全、质量与效率之间取得平衡，尤其适用于高风险或高价值任务。 ([Wikipedia](https://en.wikipedia.org/wiki/Human-in-the-loop))
- **代码解释器（Code Interpreter）**：能够执行代码、处理数据并返回结果的工具，使智能体能够进行数值计算、数据分析、可视化等任务。
- **位置编码（Positional Encoding）**：为序列中的每个位置添加位置信息，使模型能够理解序列的顺序关系。 ([Wikipedia](https://en.wikipedia.org/wiki/Positional_encoding))
- **低秩适配（LoRA, Low-Rank Adaptation）**：通过低秩矩阵分解的方式为模型添加可训练的适配器，实现参数高效的微调。 ([Wikipedia](https://en.wikipedia.org/wiki/Low-rank_adaptation))
- **元学习（Meta-learning）**：「学习如何学习」的方法族，目标是让模型通过跨任务经验获得**快速适配新任务**的能力（例如少步更新或少量上下文即可迁移）。 ([Wikipedia](https://en.wikipedia.org/wiki/Meta-learning))
- **具身智能（Embodied Intelligence）**：具身智能强调智能体通过**身体（传感器/执行器）—环境交互闭环**获得并体现智能，认知与决策与身体形态、动作能力及环境反馈紧密耦合；不限定是否人形，也不限定必须采用某一种模型或系统组件。 ([Wikipedia](https://en.wikipedia.org/wiki/Embodied_cognition))
- **分布外数据（OOD, Out-Of-Distribution）**：与训练数据分布不同的数据，模型在处理这类数据时性能可能显著下降。 ([Wikipedia](https://en.wikipedia.org/wiki/Out-of-distribution_detection))
- **分组查询注意力（GQA, Group Query Attention）**：在多头注意力基础上，多个查询头共享同一组键值对，在保持性能的同时减少计算和显存开销。
- **分词（Tokenization）**：将文本分解为词元（Token）序列的过程，是文本处理的基础步骤。 ([Wikipedia](https://en.wikipedia.org/wiki/Tokenization_(natural_language_processing)))
- **前馈神经网络（FFN, Feed-Forward Network）**：Transformer 中的全连接层，对每个位置独立应用两层线性变换和非线性激活，用于特征变换。 ([Wikipedia](https://en.wikipedia.org/wiki/Feedforward_neural_network))
- **原域（Source Domain）**：迁移学习中提供先验知识的起始数据分布/任务域，即模型主要预训练或先验学习所依赖的领域。 ([Wikipedia](https://en.wikipedia.org/wiki/Domain_adaptation))
- **参数高效微调（PEFT, Parameter-Efficient Fine-Tuning）**：只更新模型的一小部分参数（如适配器层、偏置项等）进行微调，在保持性能的同时大幅减少训练和存储成本。 ([Wikipedia](https://en.wikipedia.org/wiki/Parameter-efficient_fine-tuning))
- **反事实（Counterfactual）**：对「若某事件未发生/若采取不同干预，结果会怎样」的假设情景描述，是因果分析与决策评估的重要概念基础。 ([Wikipedia](https://en.wikipedia.org/wiki/Counterfactual_conditional))
- **反向传播（Back Propagation）**：计算损失函数对网络各层参数的梯度，从输出层向输入层逐层传播误差信号，用于参数更新的算法。 ([Wikipedia](https://en.wikipedia.org/wiki/Backpropagation))
- **向量嵌入（Vector Embedding）**：将离散或高维对象（词、句子、图像等）映射为连续向量表示，使语义或结构相似性可通过向量空间运算表达与计算。 ([Wikipedia](https://en.wikipedia.org/wiki/Word_embedding))
- **向量数据库（Vector Database）**：专门用于存储和检索高维向量数据的数据库，支持相似度搜索，常用于 RAG 系统中存储文档嵌入。 ([Wikipedia](https://en.wikipedia.org/wiki/Vector_database))
- **因果推断（Causal Inference）**：利用实验或观察数据在一定假设下估计「干预导致结果变化」的方法体系，常涉及随机试验、匹配、工具变量、差分法、因果图等。 ([Wikipedia](https://en.wikipedia.org/wiki/Causal_inference))
- **图形处理器（GPU, Graphics Processing Unit）**：专为并行计算设计的处理器，在深度学习中用于加速矩阵运算和神经网络训练。 ([Wikipedia](https://en.wikipedia.org/wiki/Graphics_processing_unit))
- **基于人类反馈的强化学习（RLHF, Reinforcement Learning from Human Feedback）**：利用人类偏好信号（评分/比较等）训练奖励模型，并通过强化学习或偏好优化方法调整策略模型，使其输出更符合人类偏好；常用于目标难以形式化为显式损失函数的对齐问题（如帮助性、无害性、风格偏好与任务质量）。 ([Wikipedia](https://en.wikipedia.org/wiki/Reinforcement_learning_from_human_feedback))
- **基于图的检索增强生成（GraphRAG）**：利用知识图谱进行检索增强生成的方法，能够捕捉实体间的关系和结构化知识。
- **基础模型（Foundation Model, FM）**：基础模型是指在**大规模、多来源数据**上进行预训练、具备较强**通用性与可适配性**的模型，可通过微调、提示学习、检索增强、工具调用等方式支持多类下游任务；其核心强调「平台化通用能力」，而非仅参数规模。 ([Wikipedia](https://en.wikipedia.org/wiki/Foundation_model))
- **多头注意力（Multi-Head Attention）**：将注意力机制并行执行多次，每次使用不同的学习到的线性变换，使模型能够同时关注不同类型的依赖关系。 ([Wikipedia](https://en.wikipedia.org/wiki/Attention_(machine_learning)#Multi-head_attention))
- **多头潜在注意力（MLA, Multi-Head Latent Attention）**：DeepSeek 等模型采用的高效注意力架构，通过潜在表示减少计算复杂度。
- **多查询注意力（MQA, Multi-Query Attention）**：所有查询头共享同一组键值对，进一步减少显存占用，常用于推理优化。
- **多模态学习（Multimodal Learning）**：联合建模并融合多种模态（文本、图像、音频等）信息的学习方法，使模型能够在跨模态理解、对齐与生成任务上提升表现。 ([Wikipedia](https://en.wikipedia.org/wiki/Multimodal_learning))
- **多步推理（Multi-step Reasoning）**：解决问题时需要经历多个依赖前一步结果的推理步骤以得到结论的过程，可发生在数学推导、规划决策、复杂问答等情境中。 ([Wikipedia](https://en.wikipedia.org/wiki/Reasoning))
- **大语言模型（LLM, Large Language Model）**：大语言模型是以语言建模目标（如下一词预测/去噪等）在大规模语料上训练、通常基于 Transformer 架构、具备较强语言理解与生成能力并呈现上下文学习与迁移泛化能力的模型；「大」常对应更大数据与计算，但不宜用固定参数门槛定义。 ([Wikipedia](https://en.wikipedia.org/wiki/Large_language_model))
- **字节对编码（BPE, Byte-Pair Encoding）**：一种子词分词算法，通过迭代合并最频繁的字符对来构建词汇表，平衡词汇表大小和未登录词问题。 ([Wikipedia](https://en.wikipedia.org/wiki/Byte_pair_encoding))
- **GUARDRAILS（安全护栏）**：用于约束与规范模型/智能体行为的机制集合，包括安全与合规策略、权限与工具调用约束、输出格式/内容限制、拒答与降级策略、事实性检查等，以提升可控性与可靠性。 ([Wikipedia](https://en.wikipedia.org/wiki/AI_safety))
- **对齐（Alignment）**：让模型的行为、输出和决策符合人类价值观、意图和偏好的过程，包括帮助性、无害性、诚实性等维度。 ([Wikipedia](https://en.wikipedia.org/wiki/AI_alignment))
- **少样本学习（Few-shot Learning）**：在样本很少的条件下完成学习或适配的设定，既可以指推理时提供少量示例的上下文学习，也可以指用少量标注进行轻量微调。 ([Wikipedia](https://en.wikipedia.org/wiki/Few-shot_learning))
- **层归一化（Layer Normalization）**：对神经网络层输出的特征进行归一化，稳定训练过程并加速收敛。 ([Wikipedia](https://en.wikipedia.org/wiki/Layer_normalization))
- **嵌入 / 词向量（Embedding）**：将离散或高维对象（词、句子、图像等）映射为连续向量表示，使语义或结构相似性可通过向量空间运算表达与计算。 ([Wikipedia](https://en.wikipedia.org/wiki/Word_embedding))
- **工作记忆（Working Memory）**：智能体在处理当前任务时临时存储和操作信息的记忆系统，容量有限但访问快速。 ([Wikipedia](https://en.wikipedia.org/wiki/Working_memory))
- **工具调用（Tool Use / Function Calling）**：智能体调用外部工具、API 或函数来执行特定操作的能力，扩展了模型的能力边界。 ([Wikipedia](https://en.wikipedia.org/wiki/Function_calling))
- **并行计算（Parallelism）**：将计算任务分解为多个部分并行执行以提高效率的方法，包括数据并行、模型并行、流水线并行等。 ([Wikipedia](https://en.wikipedia.org/wiki/Parallel_computing))
- **幻觉（Hallucination）**：在生成式模型语境中，幻觉指模型在缺乏可靠证据或超出可验证知识范围时，生成**看似合理但事实错误、不可证实、与输入/上下文不一致**或虚构来源的内容（包括事实、引用、数值、因果与细节等层面的不可靠生成）。 ([Wikipedia](https://en.wikipedia.org/wiki/Hallucination_(artificial_intelligence)))
- **序列到序列（Sequence-to-Sequence, Seq2Seq）**：将输入序列映射到输出序列的建模框架，常由编码器与解码器组成，用于机器翻译、摘要、对话等可变长序列转换任务。 ([Wikipedia](https://en.wikipedia.org/wiki/Seq2seq))
- **张量处理器（TPU, Tensor Processing Unit）**：Google 开发的专为机器学习工作负载优化的专用芯片，针对张量运算进行了优化。 ([Wikipedia](https://en.wikipedia.org/wiki/Tensor_processing_unit))
- **强化学习（RL, Reinforcement Learning）**：智能体通过与环境交互、接收奖励信号来学习最优策略的机器学习方法。 ([Wikipedia](https://en.wikipedia.org/wiki/Reinforcement_learning))
- **微调（Fine-tuning）**：在目标任务数据上继续训练预训练模型的部分或全部参数，使其适配特定任务或分布的过程。 ([Wikipedia](https://en.wikipedia.org/wiki/Fine-tuning_(deep_learning)))
- **思维树（ToT, Tree of Thoughts）**：通过构建和探索多个推理路径的树状结构来解决问题的方法，允许模型回溯和选择最优路径。
- **思维链（Chain of Thought, CoT）**：思维链通常指一种提示/输出策略，使模型将中间推理步骤以文本形式显式呈现以帮助复杂问题求解；它是「推理过程的呈现方式」，不等同于模型是否具备多步推理能力。 ([Wikipedia](https://en.wikipedia.org/wiki/Chain-of-thought_prompting))
- **情景记忆（Episodic Memory）**：存储特定事件、经历和情境的记忆，使智能体能够回忆和参考过去的经验。 ([Wikipedia](https://en.wikipedia.org/wiki/Episodic_memory))
- **批归一化（Batch Normalization）**：对每个批次的数据进行归一化，稳定训练过程并加速收敛的技术。 ([Wikipedia](https://en.wikipedia.org/wiki/Batch_normalization))
- **指令微调（Instruction Tuning）**：在（指令，输出）或（多轮对话，回复）数据上进行有监督训练，使模型学会**理解指令意图、遵循交互格式并生成符合要求的回答**；通常被视为面向「指令遵循」的 SFT 设定。 ([Wikipedia](https://en.wikipedia.org/wiki/Instruction_tuning))
- **损失函数（Loss Function）**：衡量模型预测与真实值之间差异的函数，训练过程中通过最小化损失函数来优化模型参数。 ([Wikipedia](https://en.wikipedia.org/wiki/Loss_function))
- **REACT（推理-行动闭环）**：推理与行动交替进行的范式：模型在执行过程中持续观察反馈、调整计划并选择下一步动作，以支持长程任务与不确定环境下的适应。
- **REASONING（推理闭环）**：智能体在内部对目标、约束与当前状态进行分析与规划，并根据反馈不断修正决策的循环过程（可包含计划、分解、检验与自我纠错）。 ([Wikipedia](https://en.wikipedia.org/wiki/Reasoning))
- **提示词 / 提示工程（Prompt / Prompt Engineering）**：通过设计输入提示（指令、示例、约束、格式等）来引导生成模型产生特定类型输出的实践与方法集合。 ([Wikipedia](https://en.wikipedia.org/wiki/Prompt_engineering))
- **数据并行（Data Parallelism）**：将数据批次分配到多个设备上，每个设备使用相同的模型副本处理不同的数据，然后同步梯度更新。 ([Wikipedia](https://en.wikipedia.org/wiki/Data_parallelism))
- **数据清洗（Data Cleaning）**：从原始数据中移除噪声、错误、重复和无关信息，提高数据质量的过程。 ([Wikipedia](https://en.wikipedia.org/wiki/Data_cleansing))
- **旋转位置编码（RoPE, Rotary Positional Encoding）**：通过旋转矩阵将位置信息编码到注意力计算中，能够更好地处理长序列的位置关系。
- **显存（VRAM / Memory）**：图形处理器上的高速内存，用于存储模型参数、激活值和中间计算结果。 ([Wikipedia](https://en.wikipedia.org/wiki/Video_RAM))
- **显存墙（Memory Wall）**：显存容量和带宽成为模型规模和训练速度瓶颈的现象，限制了模型的最大规模和训练效率。 ([Wikipedia](https://en.wikipedia.org/wiki/Memory_wall))
- **智能体（Agent）**：能够感知环境、做出决策并执行行动以达成目标的自主系统，在 AI 语境中通常指基于大语言模型的智能代理。 ([Wikipedia](https://en.wikipedia.org/wiki/Intelligent_agent))
- **FSM（有限状态机）**：用有限个状态及其转移规则描述系统行为的模型，常用于将复杂流程拆解为可控、可验证的状态与事件驱动逻辑。 ([Wikipedia](https://en.wikipedia.org/wiki/Finite-state_machine))
- **未登录词（OOV, Out-Of-Vocabulary）**：不在模型词汇表中的词或词元，需要通过子词分解或其他方式处理。 ([Wikipedia](https://en.wikipedia.org/wiki/Out-of-vocabulary))
- **权重衰减（Weight Decay）**：在损失函数中添加参数范数的正则化项，防止过拟合的技术，等价于 L2 正则化。 ([Wikipedia](https://en.wikipedia.org/wiki/Regularization_(mathematics)))
- **束搜索（Beam Search）**：维护多个候选序列，在每个时间步保留概率最高的 k 个候选，平衡质量和多样性的解码策略。 ([Wikipedia](https://en.wikipedia.org/wiki/Beam_search))
- **Transformer 架构（Transformer）**：基于自注意力机制的序列建模架构，无需循环或卷积结构即可处理序列数据，成为现代大语言模型的基础。 ([Wikipedia](https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)))
- **梯度下降（Gradient Descent）**：通过沿着损失函数梯度的反方向更新参数来最小化损失函数的优化算法。 ([Wikipedia](https://en.wikipedia.org/wiki/Gradient_descent))
- **梯度消失（Vanishing Gradient）**：反向传播过程中梯度在层间逐步变小，导致前层参数更新困难、训练变慢或停滞的现象。 ([Wikipedia](https://en.wikipedia.org/wiki/Vanishing_gradient_problem))
- **梯度爆炸（Exploding Gradient）**：反向传播中梯度过大导致参数更新不稳定甚至数值溢出，使训练发散的现象。 ([Wikipedia](https://en.wikipedia.org/wiki/Exploding_gradient_problem))
- **检索增强生成（RAG, Retrieval-Augmented Generation）**：结合信息检索和生成模型的方法，通过从外部知识库检索相关信息来增强生成内容的准确性和相关性。 ([Wikipedia](https://en.wikipedia.org/wiki/Retrieval-augmented_generation))
- **模型并行（Model Parallelism）**：将模型的不同部分分配到不同的设备上，每个设备负责模型的一部分计算。 ([Wikipedia](https://en.wikipedia.org/wiki/Model_parallelism))
- **残差连接（Residual Connection）**：将层的输入直接添加到输出，形成跳跃连接，有助于梯度流动和深层网络的训练。 ([Wikipedia](https://en.wikipedia.org/wiki/Residual_neural_network))
- **泛化能力（Generalization Ability）**：模型在未见过的新数据或分布轻微变化条件下仍能保持有效性能的能力，是衡量模型可靠性的核心指标之一。 ([Wikipedia](https://en.wikipedia.org/wiki/Generalization_(learning)))
- **注意力机制（Attention Mechanism）**：使模型能够关注输入序列中不同位置信息的重要性的机制，允许模型动态地选择相关信息进行处理。 ([Wikipedia](https://en.wikipedia.org/wiki/Attention_(machine_learning)))
- **注意力汇聚 / 注意力槽（Attention Sink）**：在长序列注意力计算中，某些特殊位置（如序列开头）会吸引大量注意力，这种现象称为注意力汇聚。
- **流水线并行（Pipeline Parallelism）**：将模型按层分割到多个设备上，形成流水线，不同设备同时处理不同批次的样本，提高设备利用率。 ([Wikipedia](https://en.wikipedia.org/wiki/Pipeline_parallelism))
- **涌现能力（Emergent Capability）**：模型在达到一定规模后突然出现、在较小模型中不存在的能力，如上下文学习、指令遵循、推理等。 ([Wikipedia](https://en.wikipedia.org/wiki/Emergence))
- **深度学习（Deep Learning）**：使用多层神经网络进行学习的机器学习方法，能够自动学习数据的层次化表示。 ([Wikipedia](https://en.wikipedia.org/wiki/Deep_learning))
- **深度残差网络（Residual Network, ResNet）**：通过引入残差连接（跳连）缓解深层网络训练难题（如梯度消失/退化），从而支持更深的网络结构与稳定优化。 ([Wikipedia](https://en.wikipedia.org/wiki/Residual_neural_network))
- **深度神经网络（Deep Neural Network, DNN）**：具有多层非线性变换结构的神经网络，可通过层级表示学习逼近复杂函数关系。 ([Wikipedia](https://en.wikipedia.org/wiki/Deep_learning))
- **混合专家模型（MoE, Mixture of Experts）**：将模型分解为多个专家网络，每次激活时只使用部分专家，从而在保持模型容量的同时降低计算成本。 ([Wikipedia](https://en.wikipedia.org/wiki/Mixture_of_experts))
- **温度（Temperature）**：控制生成随机性的参数，温度越高输出越随机多样，温度越低输出越确定和保守。 ([Wikipedia](https://en.wikipedia.org/wiki/Softmax_function#Temperature))
- **特征提取（Feature Extraction）**：从原始数据中构造或学习更有信息量、便于任务求解的表示（特征），以支持后续预测、决策或生成。 ([Wikipedia](https://en.wikipedia.org/wiki/Feature_extraction))
- **生成式人工智能（GenAI, Generative AI）**：生成式人工智能是指利用生成模型在给定条件（提示语、上下文、约束等）下生成新内容（文本、图像、音频、视频、代码等）的技术与系统；其关键在于「**生成**」而非「判别/分类」。 ([Wikipedia](https://en.wikipedia.org/wiki/Generative_artificial_intelligence))
- **监督学习（Supervised Learning）**：利用带标签数据学习从输入到输出的映射函数，使模型在新输入上能够预测对应输出的学习范式。 ([Wikipedia](https://en.wikipedia.org/wiki/Supervised_learning))
- **监督微调（SFT, Supervised Fine-Tuning）**：使用标注的输入-输出对进行有监督训练，使模型学会执行特定任务或遵循特定格式。 ([Wikipedia](https://en.wikipedia.org/wiki/Supervised_learning))
- **目标域（Target Domain）**：迁移学习中需要解决的新数据分布/任务域，模型通过利用原域知识提升在该域上的表现。 ([Wikipedia](https://en.wikipedia.org/wiki/Domain_adaptation))
- **知识图谱（Knowledge Graph）**：以图结构表示实体、属性和关系的知识表示方法，能够捕捉结构化知识。 ([Wikipedia](https://en.wikipedia.org/wiki/Knowledge_graph))
- **知识蒸馏（Knowledge Distillation）**：将大型教师模型的知识转移到小型学生模型中的技术，通过让学生模型学习教师模型的输出分布来实现模型压缩。 ([Wikipedia](https://en.wikipedia.org/wiki/Knowledge_distillation))
- **神经网络（Neural Network）**：受生物神经网络启发的计算模型，由相互连接的节点（神经元）组成，通过调整连接权重学习数据中的模式。 ([Wikipedia](https://en.wikipedia.org/wiki/Artificial_neural_network))
- **神经网络处理器（NPU, Neural Processing Unit）**：专为神经网络推理和训练设计的专用芯片，通常集成在移动设备或边缘计算设备中。 ([Wikipedia](https://en.wikipedia.org/wiki/Neural_processing_unit))
- **程序记忆（Procedural Memory）**：存储如何执行特定任务和操作步骤的记忆，包括技能、规则和流程。 ([Wikipedia](https://en.wikipedia.org/wiki/Procedural_memory))
- **算力 / 浮点运算次数（FLOPs, Floating Point Operations）**：衡量计算量的单位，表示执行浮点运算的次数，常用于评估模型的计算复杂度。 ([Wikipedia](https://en.wikipedia.org/wiki/FLOPS))
- **系统提示词（System Prompt）**：在对话系统中用于设定模型角色、行为准则和输出格式的提示词，通常对用户不可见但影响模型的整体行为。 ([Wikipedia](https://en.wikipedia.org/wiki/Prompt_engineering))
- **结构化数据 / 非结构化数据（Structured / Unstructured Data）**：结构化数据具有明确的格式和模式（如表格、数据库），非结构化数据没有固定格式（如文本、图像、音频）。 ([Wikipedia](https://en.wikipedia.org/wiki/Unstructured_data))
- **编码器（Encoder）**：接收输入序列并生成上下文表示（向量序列或聚合表示）的模块，为后续解码或预测提供信息基础。 ([Wikipedia](https://en.wikipedia.org/wiki/Encoder-decoder_architecture))
- **缩放定律（Scaling Law）**：模型性能随参数量、数据量、计算量增加而提升的规律，描述了模型规模与性能之间的定量关系。 ([Wikipedia](https://en.wikipedia.org/wiki/Scaling_law_(deep_learning)))
- **群体相对策略优化（GRPO, Group Relative Policy Optimization）**：基于群体比较的强化学习优化方法，用于训练语言模型。
- **自回归（Autoregressive）**：一种序列生成方式：在第 (t) 步生成输出时以此前 (1..t-1) 步的输出为条件，从而逐步生成完整序列。 ([Wikipedia](https://en.wikipedia.org/wiki/Autoregressive_model))
- **自注意力（Self-Attention）**：注意力机制的一种，其中查询、键、值均来自同一输入序列，使序列中的每个位置能够关注到序列中所有其他位置的信息。 ([Wikipedia](https://en.wikipedia.org/wiki/Attention_(machine_learning)#Self-attention))
- **自然语言处理（NLP, Natural Language Processing）**：使计算机能够理解、处理和生成人类语言的技术与方法的统称。 ([Wikipedia](https://en.wikipedia.org/wiki/Natural_language_processing))
- **苏格拉底法（Socratic Method）**：通过连续提问与反诘引导对方自我澄清与推理的对话式方法，强调暴露假设、检验逻辑与逐步逼近结论。 ([Wikipedia](https://en.wikipedia.org/wiki/Socratic_method))
- **ACTING（行动闭环）**：智能体将决策转化为对环境/工具的具体操作并获取反馈，再据此更新状态与后续行动的循环过程。
- **规划（Planning）**：智能体制定达成目标的行动序列的过程，涉及分解任务、排序步骤、处理不确定性等。 ([Wikipedia](https://en.wikipedia.org/wiki/Automated_planning_and_scheduling))
- **视觉-语言-动作模型（Vision-Language-Action Models）**：同时具备视觉感知、语言理解与动作生成/控制能力的模型类，目标是在环境中根据感知与指令产生可执行的行动策略。
- **解码器（Decoder）**：基于编码器表示与已生成内容逐步生成目标序列的模块，常以自回归方式输出。 ([Wikipedia](https://en.wikipedia.org/wiki/Encoder-decoder_architecture))
- **解码策略（Decoding Strategy）**：从模型输出的概率分布中生成文本的策略，包括贪婪搜索、采样、束搜索等方法。
- **认知架构（Cognitive Architecture）**：描述智能体如何组织感知、记忆、推理、决策等认知功能的框架，定义了智能体的「心智」结构。 ([Wikipedia](https://en.wikipedia.org/wiki/Cognitive_architecture))
- **REFLEXION（记忆与反思闭环）**：智能体在任务后对轨迹进行总结与反思，并将经验以规则、笔记或结构化记忆的形式写回，以提升后续任务表现的机制。
- **记忆系统（Memory）**：智能体中用于存储、检索和利用历史信息的机制，包括工作记忆、情景记忆、程序记忆等不同类型。 ([Wikipedia](https://en.wikipedia.org/wiki/Memory))
- **词元（Token）**：文本处理的最小单位，可以是词、子词或字符，通过分词（Tokenization）将文本转换为词元序列。 ([Wikipedia](https://en.wikipedia.org/wiki/Tokenization_(natural_language_processing)))
- **负迁移（Negative Transfer）**：由于原域与目标域差异过大或迁移方式不当，迁移引入的先验反而导致目标域性能下降的现象。 ([Wikipedia](https://en.wikipedia.org/wiki/Negative_transfer))
- **贪婪搜索（Greedy Search）**：在每个时间步选择概率最高的词元作为输出，简单但可能陷入局部最优的解码策略。 ([Wikipedia](https://en.wikipedia.org/wiki/Greedy_algorithm))
- **输出头（Head）**：位于 Backbone 之后的任务特定模块，将特征映射为最终任务输出（如分类 logits、回归值、检测框等）。
- **辛普森悖论（Simpson's Paradox）**：分组数据呈现某种趋势，但合并后趋势反转的统计现象，提示分析中必须考虑分组变量与混杂因素。 ([Wikipedia](https://en.wikipedia.org/wiki/Simpson%27s_paradox))
- **迁移学习（Transfer Learning）**：将模型在原任务/原数据分布上学到的表示或参数迁移到目标任务，以减少目标任务的数据与训练成本并提升效果的学习方法。 ([Wikipedia](https://en.wikipedia.org/wiki/Transfer_learning))
- **过拟合 / 欠拟合（Overfitting / Underfitting）**：过拟合指模型在训练集上表现良好但在测试集上表现较差，欠拟合指模型在训练集和测试集上都表现不佳，通常由于模型容量不足或训练不充分导致。 ([Wikipedia](https://en.wikipedia.org/wiki/Overfitting))
- **近端策略优化（PPO, Proximal Policy Optimization）**：一种强化学习算法，通过限制策略更新的幅度来稳定训练过程，常用于 RLHF 中优化语言模型。 ([Wikipedia](https://en.wikipedia.org/wiki/Proximal_policy_optimization))
- **通用人工智能（AGI, Artificial General Intelligence）**：具备与人类相当或超越人类的通用认知能力，能够在广泛任务和领域中灵活应用知识的人工智能系统。 ([Wikipedia](https://en.wikipedia.org/wiki/Artificial_general_intelligence))
- **量化（Quantization）**：降低模型参数和激活值的数值精度（如从 FP32 到 INT8、FP16 等）以减少显存占用和加速推理的技术。 ([Wikipedia](https://en.wikipedia.org/wiki/Quantization_(signal_processing)))
- **零样本学习（Zero-shot Learning）**：在不提供任务示例的条件下，仅凭任务描述、标签语义或通用知识完成任务的设定。 ([Wikipedia](https://en.wikipedia.org/wiki/Zero-shot_learning))
- **预训练（Pre-training）**：在大规模无标注或弱标注数据上训练模型，使其学习通用的表示和知识，为后续任务提供良好的初始化。 ([Wikipedia](https://en.wikipedia.org/wiki/Pre-training))
- **预训练模型（Pre-trained Model）**：预训练模型指已完成**预训练阶段**（通常为自监督/弱监督学习）的模型，可作为下游任务训练或推理的初始化点；「预训练」描述的是训练阶段属性，未必具备基础模型那样的通用平台特征。 ([Wikipedia](https://en.wikipedia.org/wiki/Pre-trained_model))
- **骨干网络（Backbone）**：模型中用于抽取通用特征表示的主体网络部分，常可复用或从预训练权重初始化。 ([Wikipedia](https://en.wikipedia.org/wiki/Backbone_network))
- **高带宽内存（HBM, High Bandwidth Memory）**：具有极高带宽的显存技术，常用于高性能 GPU 和 AI 加速器中。 ([Wikipedia](https://en.wikipedia.org/wiki/High_Bandwidth_Memory))
